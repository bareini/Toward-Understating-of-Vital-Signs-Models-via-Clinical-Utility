{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/bar/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "from statsmodels.tsa.holtwinters import Holt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def de_norm(pred, criteria):\n",
    "    \n",
    "    df_std = pd.read_pickle(os.path.join(Path(os.getcwd()).parents[0],'df_std.pkl'))\n",
    "    df_mean = pd.read_pickle(os.path.join(Path(os.getcwd()).parents[0],'df_mean.pkl'))\n",
    "    std = df_std[criteria]\n",
    "    mean = df_mean[criteria]\n",
    "    \n",
    "    return (pred * std) + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to play with\n",
    "\n",
    "c_type = 'step'\n",
    "imp = 'mice'\n",
    "inter = 'nointer'\n",
    "i= 0\n",
    "\n",
    "dirpath = os.path.join(Path(os.getcwd()).parents[0], 'datasets', 'train test split')\n",
    "y_test_30 = pd.read_pickle(os.path.join(dirpath, f\"./Y_{c_type}_30_test_{imp}_{inter}_{i}.pkl\"))\n",
    "X_test_30 = pd.read_pickle(os.path.join(dirpath, f\"./X_{c_type}_30_test_{imp}_{inter}_{i}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dict = OrderedDict()\n",
    "X_test_30['y_test_30']  = y_test_30['sys_30']\n",
    "ids = X_test_30['hadm_id'].unique()\n",
    "\n",
    "for idx in ids:\n",
    "    tr_dict[idx] = X_test_30.loc[X_test_30.hadm_id == idx, 'y_test_30'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend Utility\n",
    "\n",
    "According to distance from Holt ES naive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend(tr_dict):\n",
    "    trends_dict = OrderedDict()\n",
    "    \n",
    "    for k,v in tr_dict.items():\n",
    "        pred_des = [v[0], v[1]]\n",
    "        for i in range(2,len(v)):\n",
    "            des = Holt(v[:i]).fit(optimized=True)\n",
    "            pred_des.append(des.forecast(2)[0])\n",
    "        trends_dict[k] = np.array(pred_des)\n",
    "    return trends_dict\n",
    "\n",
    "# calc trend utility\n",
    "def g_trend(tr, trend):\n",
    "    return np.sqrt(np.square(tr - trend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:429: FutureWarning: After 0.13 initialization must be handled at model creation\n",
      "  FutureWarning,\n",
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:1439: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:1444: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  aicc = aic + aicc_penalty\n",
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:1445: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n"
     ]
    }
   ],
   "source": [
    "trends_dict = trend(tr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Range\n",
    "\n",
    "A naive step function implementation for samples that exceed the thersholds. For Sys thersholds are set to [90,180] to address hypotension and severe hypertension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_norm_naive_sys(tr):\n",
    "    tr = de_norm(tr, criteria='P_sys_q0.5')\n",
    "    mask_hyper = (tr > 180)\n",
    "    mask_hypo = (tr < 90)* -1\n",
    "    mask = mask_hyper + mask_hypo \n",
    "    return mask.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = {}\n",
    "\n",
    "for k,v in tr_dict.items():\n",
    "    un[k] = f_norm_naive_sys(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([156.03078887, 156.01701018, 151.05291772, ..., 157.80706512,\n",
       "       157.58100312, 158.01372649])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get pred data\n",
    "\n",
    "file = open(os.path.join(os.getcwd(), 'scatters','30_mice.pkl'), 'rb')\n",
    "sct = pkl.load(file)\n",
    "ridge_test_30 = sct['30_bp_step_nointer_mice_ridge'][0]['pred_test']\n",
    "xbg_test_30 = sct['30_bp_step_nointer_mice_ridge'][0]['pred_test']\n",
    "\n",
    "ridge_test_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr_dict = OrderedDict()\n",
    "X = X_test_30.copy()\n",
    "X['y_test_30']  = ridge_test_30\n",
    "\n",
    "for idx in ids:\n",
    "    pred_tr_dict[idx] = X.loc[X.hadm_id == idx, 'y_test_30'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:429: FutureWarning: After 0.13 initialization must be handled at model creation\n",
      "  FutureWarning,\n",
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:1439: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:1444: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  aicc = aic + aicc_penalty\n",
      "/home/bar/.local/lib/python3.6/site-packages/statsmodels/tsa/holtwinters/model.py:1445: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n"
     ]
    }
   ],
   "source": [
    "pred_trends_dict = trend(tr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pred = {}\n",
    "\n",
    "for k,v in pred_tr_dict.items():\n",
    "    un_pred[k] = f_norm_naive_sys(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Range Evaluation Measures\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    \\frac{1}{n}\\sum_{i}\\max\\left(0, (|f_{norm}\\left(y_i\\right)| - |f_{norm}\\left(y^{pred}_i\\right)\\right|) + \\max(0, sign(f_{norm}(y_i) \\cdot sign(f_{norm}(y^{pred}_i))\\\\\n",
    "    \\frac{1}{n}\\sum_{i}\\max\\left(0, |f_{norm}\\left(y^{pred}_i\\right)| - |f_{norm}\\left(y_i\\right)\\right|) + \\max(0, sign(f_{norm}(y_i)) \\cdot sign(f_{norm}(y^{pred}_i))\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_norm_eval(dict1, dict2):\n",
    "    \n",
    "    sum_norm_total = 0\n",
    "    for k,v in dict1.items():\n",
    "        sum_norm = 0\n",
    "        for i in range(len(dict1[k])):\n",
    "            sum_norm += max(0,abs(dict1[k][i]) - abs(dict2[k][i])) + max(0, -np.sign(dict1[k][i])*np.sign(dict2[k][i]))\n",
    "        sum_norm_total += sum_norm / len(dict1[k])\n",
    "    return sum_norm_total  / len(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing important: 0.0\n",
      "false alarm: 0.8480776341104778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'missing important: {f_norm_eval(un, un_pred)}')\n",
    "print(f'false alarm: {f_norm_eval(un_pred, un)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Based Evaluation\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "    W_{g}(y_i)\\cdot |y_i - y^{pred}_i|\\\\\n",
    "    W_{g}(y^{pred}_i)\\cdot |y_i - y^{pred}_i|\n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_max: 1.6043447911875044\n",
      "u_max_pred: 1.6043447911875044\n"
     ]
    }
   ],
   "source": [
    "# Calc Weights\n",
    "\n",
    "values = [v for k,v in trends_dict.items()]\n",
    "u_max = max(np.hstack(values))\n",
    "print(f'u_max: {u_max}')\n",
    "\n",
    "values = [v for k,v in pred_trends_dict.items()]\n",
    "u_max_pred = max(np.hstack(values))\n",
    "print(f'u_max_pred: {u_max_pred}')\n",
    "\n",
    "\n",
    "# calculate weights\n",
    "weights = {k:v/u_max for k,v in trends_dict.items()}\n",
    "weights_pred = {k:v/u_max for k,v in pred_trends_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weights\n",
    "\n",
    "def w_trend(dict1, dict2, w):\n",
    "    total_sum_trend = 0\n",
    "    for k,v in w.items():\n",
    "        sum_trend = 0\n",
    "        for i in range(len(dict1[k])):\n",
    "            sum_trend += w[k][i]*abs(dict1[k][i] - dict2[k][i]) / len(dict1[k])\n",
    "            \n",
    "        sum_trend += w[k][i]*abs(dict1[k][i] - dict2[k][i])\n",
    "    return np.mean(sum_trend) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing important: 0.41214923001573267\n",
      "false alarm: 0.41214923001573267\n"
     ]
    }
   ],
   "source": [
    "print(f'missing important: {w_trend(un, un_pred, weights)}')\n",
    "print(f'false alarm: {w_trend(un_pred, un, weights_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_dict= {'Normal Range Deviation Miss':f_norm_eval(un, un_pred),\\\n",
    "            'Normal Range Deviation False Alarm':f_norm_eval(un_pred, un),\\\n",
    "           'Trend Deviation Miss': w_trend(un, un_pred, weights),\\\n",
    "            'Trend Deviation False Alarm': w_trend(un_pred, un, weights_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal Range Deviation Miss</th>\n",
       "      <th>Normal Range Deviation False Alarm</th>\n",
       "      <th>Trend Deviation Miss</th>\n",
       "      <th>Trend Deviation False Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normal Range Deviation Miss  Normal Range Deviation False Alarm  \\\n",
       "1                          0.0                               0.848   \n",
       "\n",
       "   Trend Deviation Miss  Trend Deviation False Alarm  \n",
       "1                 0.412                        0.412  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pref_dict, index=[1]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
